---
draft: false
title: 'pgflow 0.12.0: Simpler Handler Signatures for Flow Composition'
description: 'Breaking change: asymmetric handler signatures remove the run wrapper, enabling functional composition'
date: 2025-12-24
authors:
  - jumski
tags:
  - release
  - breaking-change
  - migration
featured: true
---

import { Aside, Steps } from "@astrojs/starlight/components";

pgflow 0.12.0 introduces asymmetric handler signatures - a breaking change that removes the `run` wrapper from step inputs, enabling cleaner functional composition and preparing the foundation for subflows.

## What Changed

Handler signatures are now **asymmetric**. The `input.run` pattern no longer exists.

```typescript del="input" del="input.run" del="input.dep" ins="flowInput" ins="deps" ins="async " ins="deps, ctx" ins="(await ctx.flowInput)"

// Root steps
(input) => input.run.xxx
(flowInput) => flowInput.xxx

// Dependent steps
(input) => input.dep.xxx
(deps) => deps.dep.xxx

// Dependent needing flowInput
(input) => input.run.xxx
async (deps, ctx) => (await ctx.flowInput).xxx
```

<Aside type="caution" title="Breaking Change">
All handler signatures must be updated. See migration examples below.
</Aside>

## Why This Change?

The previous `run` wrapper blocked functional composition:

```typescript
// OLD: The run wrapper created type mismatches
// Root steps received: { run: flowInput }
// Dependent steps received: { run: flowInput, dep1: output1 }

// This meant subflows couldn't compose cleanly:
const ChildFlow = new Flow<{ data: string }>()
  .step({ slug: "process" }, (input) => {
    // Expected: input.data
    // Received: { run: parentInput, prep: { data: "..." } }
    // TYPE MISMATCH!
  });
```

By removing the wrapper, outputs from one flow can become inputs to another without transformation.

<Aside type="note" title="Future Feature">
Flow composition (subflows) will be implemented in upcoming releases. This breaking change lays the groundwork by ensuring handler signatures are compatible with composable flows.
</Aside>

## Upgrading Your Flows

Apply these patterns to update your handlers. The red/green highlights show exactly what changes.

<Aside type="tip" title="Why is ctx.flowInput async?">
`ctx.flowInput` is lazy-loaded to prevent data duplication. For map steps processing thousands of items, including the full flow input in each task would multiply data transfer. Instead, it's fetched on-demand and cached per run.
</Aside>

### Migration Patterns

#### Root Steps (same for `.step` and `.array`)

```typescript del="input" del="input.run" ins="flowInput"
// BEFORE
.step({ slug: 'init' }, (input) => {
  return { userId: input.run.userId };
})

// AFTER
.step({ slug: 'init' }, (flowInput) => {
  return { userId: flowInput.userId };
})
```

#### Dependent Steps - Needing flowInput

```typescript del="input" del="input.run" del="input.init" ins="async" ins="deps, ctx" ins="await ctx.flowInput" ins="deps.init"
// BEFORE
.step({ slug: 'process', dependsOn: ['init'] }, (input) => {
  const config = input.run.config;
  const data = input.init.data;
  return combine(data, config);
})

// AFTER (must be async)
.step({ slug: 'process', dependsOn: ['init'] }, async (deps, ctx) => {
  const flowInput = await ctx.flowInput;
  const config = flowInput.config;
  const data = deps.init.data;
  return combine(data, config);
})
```

#### Dependent Steps - Not Needing flowInput (Common Case)

```typescript del="input" del="input.process" ins="deps" ins="deps.process"
// BEFORE
.step({ slug: 'save', dependsOn: ['process'] }, (input) => {
  return saveToDb(input.process.result);
})

// AFTER
.step({ slug: 'save', dependsOn: ['process'] }, (deps) => {
  return saveToDb(deps.process.result);
})
```

#### Map Steps (no change needed if only using `item`)

Most map steps just use `item` and need no changes. Only update if you need `flowInput`:

```typescript ins="async" ins="item, ctx" ins="await ctx.flowInput"
// BEFORE (accessing flowInput)
.map({ slug: 'transform', array: 'items' }, (item) => {
  return process(item);
})

// AFTER (must be async to access flowInput)
.map({ slug: 'transform', array: 'items' }, async (item, ctx) => {
  const flowInput = await ctx.flowInput;
  return process(item, flowInput.options);
})
```

### Production Upgrade Guide

The upgrade requires careful coordination to avoid running old code against the new SQL schema.

<Aside type="danger" title="Critical: No Workers Running During Migration">
It is **very important** to ensure:
- All worker functions are **disabled** (step 2)
- All existing workers have **stopped** (steps 3-4)

Running workers with old handler signatures against the new SQL schema will cause failures. Deprecated workers will gracefully finish their current task and exit - wait for this to complete before proceeding with the migration.
</Aside>

<Steps>

1. **Update handlers locally and test**

   Update all your flow handlers to the new signatures. Test locally:

   ```bash frame="none"
   npx supabase functions serve my-worker
   ```

2. **Disable worker functions**

   Prevent cron from starting new workers with old code:

   ```sql
   UPDATE pgflow.worker_functions
   SET enabled = false
   WHERE function_name = 'my-worker';
   ```

3. **Deprecate existing workers**

   ```sql
   UPDATE pgflow.workers
   SET deprecated_at = NOW()
   WHERE function_name = 'my-worker'
     AND deprecated_at IS NULL;
   ```

   Deprecated workers finish their current task but won't call `start_tasks` again - so they won't be affected by the SQL changes.

4. **Wait for workers to stop**

   Monitor workers until all have exited:

   ```sql
   SELECT COUNT(*) FROM pgflow.workers
   WHERE function_name = 'my-worker'
     AND stopped_at IS NULL;
   ```

   Wait until this returns `0` before proceeding.

5. **Apply database migration**

   ```bash frame="none"
   npx supabase db push
   ```

6. **Deploy new workers**

   ```bash frame="none"
   npx supabase functions deploy my-worker
   ```

7. **Enable worker functions**

   ```sql
   UPDATE pgflow.worker_functions
   SET enabled = true
   WHERE function_name = 'my-worker';
   ```

   The pgflow cron automatically starts new workers within seconds.

</Steps>

## Other Fixes

- Fixed `CONNECT_TIMEOUT` errors on Lovable.dev by switching to `jsr:@oscar6echo/postgres` fork
- Fixed `setTimeout` context binding issue in `@pgflow/client` for browser compatibility

---

Questions or issues? Join the [Discord community](https://discord.gg/pgflow) or [open a GitHub issue](https://github.com/pgflow-dev/pgflow/issues).
