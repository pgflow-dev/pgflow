---
draft: false
title: 'pgflow 0.7.0: Public Beta with Map Steps and Documentation Redesign'
description: 'pgflow enters public beta with parallel array processing, redesigned docs, and enhanced developer experience'
date: 2025-10-19
authors:
  - jumski
tags:
  - release
  - map-steps
  - documentation
  - public-beta
  - core
  - dsl
  - cli
  - client
featured: true
cover:
  alt: 'Cyberpunk workflow engine with glowing teal circuits processing parallel data streams'
  image: '../../../assets/cover-images/pgflow-0-7-0-public-beta-map-steps-and-documentation-redesign.png'
---

import { Aside, Code } from "@astrojs/starlight/components";
import preMigrationCheck from '../../../../../core/queries/PRE_MIGRATION_CHECK_20251006073122.sql?raw';

pgflow 0.7.0 is here - a major milestone that brings parallel array processing,
production-ready stability, and a complete documentation redesign.

## pgflow Enters Public Beta

pgflow has transitioned from alpha to **public beta**. Core functionality is stable and reliable,
with early adopters already running pgflow in production environments.

This milestone reflects months of testing, bug fixes, and real-world usage feedback. The SQL Core,
DSL, and Edge Worker components have proven robust across different workloads and deployment scenarios.

See the [project status page](/project-status/) for production recommendations and known limitations.

## Map Steps

Map steps enable parallel array processing by automatically creating multiple tasks - one for each array element.

```typescript
import { Flow } from '@pgflow/dsl/supabase';

const BatchProcessor = new Flow<string[]>({
  slug: 'batchProcessor',
  maxAttempts: 3,
})
  .map(
    { slug: 'processUrls' },
    async (url) => {
      // Each URL gets its own task with independent retry
      return await scrapeWebpage(url);
    }
  );
```

**Why this matters:**

When processing 100 URLs, if URL #47 fails, only that specific task retries - the other 99 continue
processing. With a regular step, one failure would retry all 100 URLs.

This independent retry isolation makes flows more efficient and resilient. Each task has its own
retry counter, timeout, and execution context.

Map steps handle edge cases automatically:
- Empty arrays complete immediately without creating tasks
- Type violations fail gracefully with stored output for debugging
- Results maintain array order regardless of completion sequence

Learn more: [Map Steps](/concepts/map-steps/) and [Process Arrays in Parallel](/build/process-arrays-in-parallel/)

## Array Steps

The new `.array()` method provides compile-time type safety for array-returning handlers:

```typescript
// Enforces array return type at compile time
flow.array({ slug: 'items' }, () => [1, 2, 3]);  // Valid

flow.array({ slug: 'invalid' }, () => 42);  // Compile error
```

Array steps are a semantic wrapper that makes intent clear and moves type errors from `.map()` to `.array()`. When a map step depends on a regular step that doesn't return an array, the compiler catches it too - `.array()` just makes the error location more precise and the code intention explicit.

## TypeScript Client - Now Fully Documented

The **`@pgflow/client`** package, initially released in v0.4.0 but never widely announced, now has complete documentation. This **type-safe client** powers the [pgflow demo](https://www.pgflow.dev/demo/) and provides both **promise-based and event-based APIs** for starting workflows and monitoring real-time progress from TypeScript environments (browsers, Node.js, Deno, React Native).

Features include **type-safe flow management** with automatic inference from flow definitions, **real-time progress monitoring** via Supabase broadcasts, and extensive test coverage.

**Learn more:** [TypeScript Client Guide](/build/starting-flows/typescript-client/) | [@pgflow/client API Reference](/reference/pgflow-client/)

## Documentation Restructure and New Landing Page

The entire documentation has been reorganized from a feature-based structure to a
**user-journey-based structure**, making it easier to find what you need at each stage of using pgflow.

import docsBefore from '../../../assets/news-images/pgflow-0-7-0-public-beta-map-steps-and-documentation-redesign/docs-before.png';
import docsAfter from '../../../assets/news-images/pgflow-0-7-0-public-beta-map-steps-and-documentation-redesign/docs-after.png';

| Before | After |
|--------|-------|
| <img src={docsBefore.src} alt="Documentation structure before reorganization" /> | <img src={docsAfter.src} alt="Documentation structure after reorganization" /> |

New documentation includes:
- [Build section](/build/) - Guides for starting flows, organizing code, processing arrays, and managing versions
- [Deploy section](/deploy/) - Production deployment guides for Supabase
- [Concepts](/concepts/) - Understanding map steps, context object, data model, and architecture
- [@pgflow/client API Reference](/reference/pgflow-client/) - Complete client library documentation

### Redesigned Landing Page

The homepage has been completely rebuilt with animated DAG visualization, interactive before/after code comparisons, and streamlined messaging. Visit [pgflow.dev](https://www.pgflow.dev/) to explore the new experience.

## Developer Experience Improvements

import contextualMenuImage from '../../../assets/news-images/pgflow-0-7-0-public-beta-map-steps-and-documentation-redesign/contextual-menu.png';

<div style="display: flex; gap: 1.5rem; align-items: start; margin-bottom: 1.5rem;">
  <div style="flex: 1;">
    <strong>Copy to Markdown on All Docs Pages</strong> - Every documentation page now includes contextual menu buttons to copy the page as markdown or open it directly in Claude Code or ChatGPT for context-aware assistance.
  </div>
  <div style="flex: 1;">
    <img src={contextualMenuImage.src} alt="Contextual menu showing copy to markdown and open in AI options" style="border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
  </div>
</div>

Additional improvements:
- **Full deno.json Support** - `pgflow compile` now uses `--config` flag for complete deno.json support
- **Fixed config.toml Corruption** - CLI no longer corrupts minimal config.toml files (thanks to [@DecimalTurn](https://github.com/DecimalTurn))
- **Better Type Inference** - Improved DSL type inference for `.array()` and `.map()` methods
- **Compile-time Duplicate Slug Detection** - Prevents duplicate step slugs before deployment

## Reliability Improvements

- **Enhanced Failure Handling** - Automatic archival of queued messages when runs fail, with stored output for debugging
- **Fixed Data Pruning Bug** - Resolved foreign key constraint issue preventing cleanup operations
- Comprehensive integration tests for map steps and enhanced type testing infrastructure

## Upgrading to 0.7.0

<Aside type="caution" title="Data Migration Included">
This release includes automatic data migration that modifies existing `step_states` rows for map step support. For production environments, run the [pre-migration check query](https://github.com/pgflow-dev/pgflow/blob/main/pkgs/core/queries/PRE_MIGRATION_CHECK_20251006073122.sql) to verify safety before upgrading.
</Aside>

See the [update guide](/deploy/update-pgflow/) for complete instructions.

---

**Questions or issues with the upgrade?** Join our [Discord community](https://www.pgflow.dev/discord/)
or [open an issue on GitHub](https://github.com/pgflow-dev/pgflow/issues).
