---
title: Organize Flows codebase
description: Learn how to structure your pgflow codebase for maintainability and reusability
---

import { Aside, Steps, Tabs, TabItem } from "@astrojs/starlight/components";
import { FileTree } from '@astrojs/starlight/components';
import NotProductionReady from '@/components/NotProductionReady.astro';

<NotProductionReady />

This guide outlines best practices for organizing your pgflow codebase to improve maintainability, reusability, and clarity.

## Recommended Project Structure

A well-organized pgflow project typically follows this structure:

```bash frame="none"
mkdir -p supabase/functions/_flows supabase/functions/_tasks
```

<FileTree>
- supabase
  - functions
    - _flows
      - analyze_website.ts
    - _tasks
      - scrapeWebsite.ts
      - summarizeWithAI.ts
      - extractTags.ts
      - saveWebsite.ts
    - utils.ts
</FileTree>

This organization separates your codebase into two key parts:

- `_tasks/` - Contains small, focused functions that each perform a single unit of work with clear inputs and outputs
- `_flows/` - Contains definitions that compose these tasks into directed acyclic graphs (DAGs), defining data dependencies between tasks

Tasks are modular, reusable functions designed for a specific purpose, while flows define the execution order, parallelism, and data transformations between tasks. The flow orchestrates how data moves through the computational graph.

## Task Design Best Practices

Design your task functions to be as agnostic as possible about where their inputs come from. A well-designed task should:

- Accept simple, focused parameters (like a URL or content string)
- Perform one specific job well
- Return clear results without assuming how they'll be used
- Have no knowledge about other tasks or the overall flow

**DO:**
```typescript
// Good: Task accepts direct content parameter
async function summarizeContent(content: string) {
  // Process the content directly
  return { summary: "Processed summary..." };
}

// In your flow:
.step(
  { slug: 'summary', dependsOn: ['website'] },
  async (input) => await summarizeContent(input.website.content)
)
```

**DON'T:**
```typescript
// Bad: Task expects specific step structure
async function summarizeWebsite(input: { website: { content: string } }) {
  // Tightly coupled to previous step name and structure
  return { summary: "Processed summary..." };
}

// In your flow:
.step(
  { slug: 'summary', dependsOn: ['website'] },
  async (input) => await summarizeWebsite(input) // Passing entire input object
)
```

This makes tasks reusable across different flows and easier to test in isolation.

## Example: Website Analysis Flow Implementation

Let's look at how a real-world workflow might be organized:

<Tabs>
  <TabItem label="scrapeWebsite.ts">
  ```typescript title="supabase/functions/_tasks/scrapeWebsite.ts"
  /**
   * Fetches website content from a URL
   *
   * For a real implementation, see the demo app:
   * https://github.com/pgflow-dev/pgflow/tree/main/examples/playground/supabase/functions/_tasks/scrapeWebsite.ts
   */
  export default async function scrapeWebsite(url: string) {
    console.log(`Fetching content from: ${url}`);

    // In a real implementation, this would fetch and process actual website content
    // This simplified version returns mock data based on the URL

    return {
      content: `Sample content from ${url}. This is a placeholder for real website content.
      The website discusses various topics including technology, data processing, and workflows.
      In a production app, this would be actual content scraped from the URL.`
    };
  }
  ```
  </TabItem>

  <TabItem label="summarizeWithAI.ts">
  ```typescript title="supabase/functions/_tasks/summarizeWithAI.ts"
  /**
   * Summarizes text content using AI
   *
   * For a real implementation using Groq/OpenAI, see the demo app:
   * https://github.com/pgflow-dev/pgflow/tree/main/examples/playground/supabase/functions/_tasks/summarizeWithAI.ts
   */
  export default async function summarizeWithAI(content: string) {
    console.log(`Summarizing ${content.length} chars of content`);

    // Simple function that generates a summary based on content length
    // In a real implementation, this would use an AI service API

    const length = content.length;
    let summary = "";

    if (length < 100) {
      summary = "Very short content about a website.";
    } else if (length < 500) {
      summary = "Website discussing technology and data workflows. The site includes information about processing data efficiently.";
    } else {
      summary = "Comprehensive website covering multiple aspects of technology, data processing workflows, and system architecture. The content explores efficient data handling methodologies and implementation patterns.";
    }

    return summary;
  }
  ```
  </TabItem>

  <TabItem label="extractTags.ts">
  ```typescript title="supabase/functions/_tasks/extractTags.ts"
  /**
   * Extracts relevant tags from content
   *
   * For a real implementation using AI services, see the demo app:
   * https://github.com/pgflow-dev/pgflow/tree/main/examples/playground/supabase/functions/_tasks/extractTags.ts
   */
  export default async function extractTags(content: string) {
    console.log(`Extracting tags from ${content.length} chars of content`);

    // Simple mock implementation that returns tags based on content
    // In a real implementation, this would use AI to analyze the content

    // Create a set of default tags
    const defaultTags = ["technology", "data", "workflow"];

    // Add additional tags based on content
    const additionalTags = [];
    if (content.includes("processing")) additionalTags.push("processing");
    if (content.includes("API") || content.includes("api")) additionalTags.push("api");
    if (content.includes("database") || content.includes("SQL")) additionalTags.push("database");

    return {
      keywords: [...defaultTags, ...additionalTags]
    };
  }
  ```
  </TabItem>

  <TabItem label="saveWebsite.ts">
  ```typescript title="supabase/functions/_tasks/saveWebsite.ts"
  /**
   * Saves website data to the database
   *
   * For a real implementation using Supabase, see the demo app:
   * https://github.com/pgflow-dev/pgflow/tree/main/examples/playground/supabase/functions/_tasks/saveWebsite.ts
   */
  export default async function saveWebsite(websiteData: {
    website_url: string;
    summary: string;
    tags: string[];
  }) {
    console.log("Saving website data:", websiteData);

    // In a real implementation, this would save to a database
    // This simplified version just logs and returns mock data

    // Generate a mock ID based on URL
    const id = `website_${Date.now()}`;

    return {
      success: true,
      website: {
        id,
        ...websiteData,
        created_at: new Date().toISOString()
      }
    };
  }
  ```
  </TabItem>
</Tabs>

And the flow definition that ties everything together:

```typescript title="supabase/functions/_flows/analyze_website.ts"
import { Flow } from '@pgflow/dsl';
import scrapeWebsite from '../_tasks/scrapeWebsite.ts';
import summarizeWithAI from '../_tasks/summarizeWithAI.ts';
import extractTags from '../_tasks/extractTags.ts';
import saveWebsite from '../_tasks/saveWebsite.ts';

type Input = {
  url: string;
};

export default new Flow<Input>({
  slug: 'analyze_website',
  maxAttempts: 3,
  timeout: 4,
  baseDelay: 1,
})
  .step(
    { slug: 'website' },
    async (input) => await scrapeWebsite(input.run.url),
  )
  .step(
    { slug: 'summary', dependsOn: ['website'] },
    async (input) => await summarizeWithAI(input.website.content),
  )
  .step({ slug: 'tags', dependsOn: ['website'] }, async (input) => {
    const { keywords } = await extractTags(input.website.content);
    return keywords;
  })
  .step({ slug: 'saveToDb', dependsOn: ['summary', 'tags'] }, async (input) => {
    const websiteData = {
      website_url: input.run.url,
      summary: input.summary,
      tags: input.tags,
    };
    const { website } = await saveWebsite(websiteData);

    return website;
  });
```

## Benefits of This Organization

Organizing your code this way provides several benefits:

1. **Reusability**: Tasks can be reused across multiple flows
2. **Testability**: Individual tasks can be tested in isolation
3. **Maintainability**: Easier to understand, debug, and update
4. **Separation of concerns**: Clear boundaries between logic and orchestration
5. **Versioning**: Simplifies flow versioning while maintaining task compatibility

<Aside>
**Note about JSON Serialization**: All step inputs and outputs MUST be JSON-serializable, as pgflow stores these values in JSONB database columns. This means you should use only plain objects, arrays, and primitive types (strings, numbers, booleans, null). Convert non-serializable types like Date objects to strings (`new Date().toISOString()`).
</Aside>

## Tips for Large-Scale Projects

For larger projects with many flows and tasks:

1. **Group by domain**: Consider organizing tasks by domain or functionality
2. **Shared utilities**: Create a `_utils` directory for shared helper functions
3. **Typed interfaces**: Define clear interfaces for task inputs and outputs
4. **Documentation**: Document the purpose and requirements of each task
5. **Versioning strategy**: Develop a strategy for versioning flows and tasks
6. **Testing**: Create unit tests for each task to validate functionality

<FileTree>
- supabase
  - functions
    - _flows
      - user
        - register_user.ts
        - update_profile.ts
      - content
        - publish_article.ts
        - analyze_website.ts
    - _tasks
      - user
        - validateUserData.ts
        - createUserRecord.ts
      - content
        - scrapeWebsite.ts
        - summarizeWithAI.ts
      - shared
        - sendEmail.ts
        - logActivity.ts
    - _utils
      - database.ts
      - validation.ts
</FileTree>

With this approach, you can build a maintainable, scalable pgflow codebase that grows with your application needs.
