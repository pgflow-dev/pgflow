---
title: Deploy to Supabase.com (With Limitations)
description: Deploy Edge Workers to production with current workarounds. Includes manual worker management steps and known limitations.
sidebar:
  order: 110
---

import { Aside, Steps } from "@astrojs/starlight/components";

This guide walks you through deploying pgflow Edge Workers to your production Supabase project.

<Aside type="caution" title="Current Limitations">
Deploying to production currently has a significant limitation: workers don't automatically terminate when deploying new versions. This means you'll need to manually manage worker lifecycle. We're actively working on a solution - follow the <a href="https://github.com/orgs/pgflow-dev/discussions/171">GitHub discussion</a> for updates.
</Aside>

## Prerequisites

Before deploying your Edge Worker, ensure you have:

<Steps>
1. **pgflow installed and configured** in your Supabase project
2. **Database connection string** prepared (see [Prepare DB Connection String](/how-to/prepare-db-string/))
3. **Environment variables** set in your Supabase dashboard:
   - `EDGE_WORKER_DB_URL` - Your pooled connection string (transaction mode)
   - `PGFLOW_WORKER_ID` - A unique identifier for this worker (e.g., `worker-1`)
4. **Supabase CLI** authenticated with your project
</Steps>

## Deploying Workers

Workers are Edge Functions that process tasks from your pgflow queues. They automatically respawn when CPU or wall clock limits are reached ([see Supabase limits](https://supabase.com/docs/guides/functions/limits)).

### Deploy Your Worker

```bash frame="none"
npx supabase functions deploy pgflow-worker
```

<Aside type="caution" title="Known Issue: Worker Management">
Currently, deploying a new version does NOT automatically terminate the previous worker. This is a known limitation that can lead to multiple worker versions running simultaneously, potentially causing duplicate task processing.

We're actively working on a fix. Track progress in this <a href="https://github.com/orgs/pgflow-dev/discussions/171">GitHub discussion</a>.

**Workaround**: Remove old workers manually from the Supabase dashboard before deploying new versions.
</Aside>

## Starting Workers

Start your worker with an authenticated HTTP request:

```bash frame="none"
curl -L -X POST 'https://<project-ref>.supabase.co/functions/v1/pgflow-worker' \
  -H 'Authorization: Bearer <your-anon-key>' \
  -H 'Content-Type: application/json'
```

The worker will begin processing tasks immediately and auto-respawn when terminated.

### Verify Worker is Running

Check your worker status in the Supabase dashboard under **Functions â†’ Logs**. You should see:
- Initial startup message: `Starting pgflow worker...`
- Periodic heartbeat messages
- Task processing logs

## Managing Workers

### Stopping Workers

To stop a worker, remove it from the Supabase Dashboard under **Functions**. The worker will continue processing its current task and stop when it reaches the next execution limit.

### Scaling Workers

For higher throughput, deploy multiple workers with different IDs:

```bash frame="none"
# Deploy additional workers
npx supabase functions deploy pgflow-worker-2
npx supabase functions deploy pgflow-worker-3
```

Each worker processes tasks independently, providing horizontal scaling.

## Recommended: Ensuring Worker Restarts

Due to the current worker management limitations, it's strongly recommended to set up a cron job that ensures your worker restarts if it stops:

<Steps>
1. **Create a cron function** following [Supabase's cron guide](https://supabase.com/docs/guides/cron/quickstart#invoke-supabase-edge-function-every-30-seconds)
2. **Set the schedule** to run every 5 seconds: `*/5 * * * * *`
3. **Configure the HTTP request** with your project's ANON key in the Authorization header
</Steps>

This ensures your worker restarts quickly if it ever fails unexpectedly.

## Monitoring in Production

### Key Metrics to Track

- **Worker uptime** - Check Functions logs for consistent heartbeats
- **Task processing rate** - Monitor `pgflow.step_states` for completion times
- **Error rates** - Watch for failed tasks in `pgflow.step_states`
- **Queue depth** - Monitor pending tasks to ensure workers keep up

### Recommended Alerts

<Aside type="tip">
Set up alerts for:
- Worker hasn't logged a heartbeat in 5 minutes
- Failed task rate exceeds 5%
- Queue depth growing continuously
</Aside>

## Troubleshooting Common Issues

### Worker Not Starting
- Verify your ANON key is correct
- Check Functions logs for error messages
- Ensure DATABASE_URL is properly set

### Tasks Not Processing
- Confirm worker is running (check logs)
- Verify database connection string includes pooler
- Check for tasks in `SELECT * FROM pgmq.queue_pgflow_tasks`

### High Error Rate
- Review worker logs for specific errors
- Check if tasks are timing out (increase timeout in flow definition)
- Ensure external APIs/services are accessible from Supabase

## Should You Deploy to Production?

Given the current worker management limitations, consider these factors:

**Good fit if:**
- You can tolerate manual worker management
- Your workload allows for scheduled maintenance windows
- You're comfortable with the workarounds described above

**Wait for updates if:**
- You need fully automated deployments
- Zero-downtime deployments are critical
- You can't risk duplicate task processing

<Aside type="tip" title="Stay Updated">
Follow the <a href="https://github.com/orgs/pgflow-dev/discussions/171">GitHub discussion</a> for updates on automatic worker termination. Once resolved, production deployments will be much simpler.
</Aside>
