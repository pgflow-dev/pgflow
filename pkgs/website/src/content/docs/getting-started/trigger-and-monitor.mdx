---
title: Trigger and monitor flows
description: Learn how to start a pgflow worker, trigger your workflow, and monitor execution progress
sidebar:
  order: 3
---

import { Aside, Steps, Tabs } from "@astrojs/starlight/components";
import { FileTree } from '@astrojs/starlight/components';
import NotProductionReady from '@/components/NotProductionReady.astro';

Now that you've defined and compiled your workflow, it's time to execute it!

<NotProductionReady />

In this guide, we'll set up an Edge Worker to process your workflow tasks, trigger your first flow, and observe its execution.

<Aside type="caution" title="Prerequisites">
Before starting, make sure you have:
- Completed the [Create your first flow](/getting-started/create-first-flow/) guide
- Completed the [Edge Worker installation](/edge-worker/getting-started/install-edge-worker/)
</Aside>

## 1. Create a worker function

Create a new Edge Function that will process tasks for your workflow:

```bash frame="none"
mkdir -p supabase/functions/analyze_website_worker
```

Create an `index.ts` file in the new function directory:

```typescript title="supabase/functions/analyze_website_worker/index.ts"
import { EdgeWorker } from "jsr:@pgflow/edge-worker@0.0.4";
import AnalyzeWebsite from '../_flows/analyze_website.ts';

// Pass the flow definition to the Edge Worker
EdgeWorker.start(AnalyzeWebsite);
```

<Aside>
The Edge Worker will:
1. Poll for tasks on the `analyze_website` queue
2. Process tasks based on the step slug
3. Return the appropriate result for each step
4. Handle retries if any step fails
</Aside>

### Disable JWT verification

Disable JWT verification for now by editing `supabase/config.toml`:

```diff lang="toml"
  [functions.analyze_website_worker]
  enabled = true
- verify_jwt = true
+ verify_jwt = false
  import_map = "./functions/analyze_website_worker/deno.json"
```

## 2. Start the Edge Runtime

Start the Edge Runtime to make your worker function available:

```bash frame="none"
npx supabase functions serve
```

This will start the Edge Runtime server but not yet start your worker.

## 3.  Start your worker

In a new terminal, send an HTTP request to start your worker:

```bash frame="none"
curl http://localhost:54321/functions/v1/analyze_website_worker
```

You should see output in your Edge Runtime terminal indicating the worker has started:

```
[Info] worker_id=<uuid> [WorkerLifecycle] Ensuring queue 'analyze_website' exists...
[Info] worker_id=<uuid> [WorkerLifecycle] Active and listening for tasks...
```

:::caution
If you have troubles starting the worker, make sure you disabled JWT verification in the previous step.
:::

## 4. Trigger your first flow

Now let's start a flow run! Using Supabase Studio:

1. Open Supabase Studio in your browser (typically at http://localhost:54323)
2. Navigate to the **SQL Editor**
3. Execute this SQL to start your workflow:

```sql
SELECT * FROM pgflow.start_flow(
  flow_slug => 'analyze_website',
  input => '{"url": "https://example.com"}'::jsonb
);
```

This will:
1. Create a new run for your workflow
2. Start the root steps
3. Return information about the new run

The output should look like:

```
run_id                               | flow_slug       | status  | input                         | output | remaining_steps
--------------------------------------+-----------------+---------+-------------------------------+--------+-----------------
11111111-2222-3333-4444-555555555555 | analyze_website | started | {"url": "https://example.com"} | null   | 4
```

## 5. Monitor execution

Your worker should start processing tasks immediately. You should see log output in the Edge Runtime terminal as each step executes.

You can monitor the run status using Supabase Studio:

1. In the SQL Editor, run this query:

```sql
SELECT * FROM pgflow.runs
WHERE flow_slug = 'analyze_website'
ORDER BY created_at DESC
LIMIT 1;
```

As steps complete, you'll see the `remaining_steps` count decrease. When it reaches 0, the run will be marked as `completed`:

```
run_id                               | flow_slug       | status    | input                         | output                                                  | remaining_steps
--------------------------------------+-----------------+-----------+-------------------------------+---------------------------------------------------------+-----------------
11111111-2222-3333-4444-555555555555 | analyze_website | completed | {"url": "https://example.com"} | {"save_results": {"status": "success"}}                 | 0
```

## 6. View step states

To see the status of individual steps:

1. In the SQL Editor, run this query (replace the run_id with yours):

```sql
SELECT step_slug, status, attempts, output
FROM pgflow.step_states
WHERE run_id = '11111111-2222-3333-4444-555555555555';
```

This will show the status and output of each step:

```
step_slug        | status    | attempts | output
-----------------+-----------+----------+----------------------------------------------------------
website          | completed | 1        | {"content": "<html><body>This is content...</body></html>", "status": 200}
tags             | completed | 1        | ["technology", "data", "workflow"]
summary          | completed | 1        | "This is a website about important topics."
saveToDb         | completed | 1        | {"id": "1111-11111....", "summary": "....."}
```

<Aside type="tip" title="Flow Visualization">
In a real application, you'd likely want to create a dashboard to visualize your flows and their execution status.

pgflow stores all the information needed to build rich visualizations of your workflow execution, including:
- Step dependencies
- Execution times
- Retry attempts
- Inputs and outputs

This data is available through SQL queries to the pgflow schema tables.
</Aside>

## What's happening behind the scenes?

When you trigger a workflow:

1. **Flow Initialization**:
   - A new run is created in `pgflow.runs`
   - States for all steps are created in `pgflow.step_states`
   - Tasks for root steps are created in `pgflow.step_tasks`
   - Messages are sent to the queue for root steps

2. **Task Processing**:
   - The worker polls the queue for available tasks
   - For each task, it executes the appropriate step handler
   - After successful execution, it calls `pgflow.complete_task`
   - If a step fails, it calls `pgflow.fail_task` which may retry the task

3. **Dependency Resolution**:
   - When a step completes, its dependent steps become eligible for execution
   - The system automatically creates tasks for these dependent steps
   - The process continues until all steps complete or the workflow fails

4. **Run Completion**:
   - When all steps complete, the run is marked as completed
   - The outputs from all leaf steps (those with no dependents) are collected as the run output

## Congratulations!

You've successfully:
- Created a workflow definition
- Compiled it to SQL
- Set up a worker to process tasks
- Triggered a flow execution
- Monitored its progress

This completes the pgflow getting started guide. You now have all the basics needed to start building your own workflows!

## Next steps

- Explore more complex workflows with conditional branches
- Implement real business logic in your step handlers
- Deploy your workflows to production
- Set up monitoring and alerting
- Build a UI to visualize and manage your workflows
