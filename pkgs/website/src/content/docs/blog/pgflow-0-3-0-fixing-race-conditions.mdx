---
title: 'pgflow 0.3.0: Fixing Race Conditions with Two-Phase Polling'
description: 'How we eliminated subtle race conditions in pgflow by moving from single-phase to two-phase polling, and what this means for your workflows.'
date: 2025-01-09
# lastUpdated: 2025-01-09
authors:
  - jumski
tags:
  - release
  - mvcc
  - bugfix
  - postgres
featured: true
cover:
  alt: 'Cyberpunk scene showing SQL brain in glass container with robotic arms coordinating database operations while edge workers process tasks on conveyor belts'
  image: '../../../assets/cover-images/pgflow-0-3-0-fixing-race-conditions.png'
topic: blog
id: blog
sidebar:
  order: 1
---

import { Aside, Steps } from "@astrojs/starlight/components";

pgflow 0.3.0 is here with a critical fix for race conditions that could cause tasks to be lost or duplicated under high concurrency. This release introduces **two-phase polling** to eliminate these issues while improving observability and reliability.

## The Problem: When Scaling Reveals Hidden Bugs

The race condition bug was particularly sneaky because it only appeared when scaling horizontally. With a single Edge Worker, everything worked perfectly. But as soon as multiple workers started polling simultaneously‚Äîespecially on slower production hardware‚Äîusers began experiencing:

- **Constraint violations**: `PostgresError: more than one row returned by a subquery` 
- **Lost tasks**: Messages read from the queue but never processed
- **Inconsistent behavior**: Works locally but fails in production

The irony? This bug was introduced by commit [2f13e8b90](https://github.com/pgflow-dev/pgflow/commit/2f13e8b90b3fbf57c0d1ba7299d1aad85d06ca1f) which was intended to **fix latency issues** but inadvertently created a much more serious concurrency problem.

## Understanding the MVCC Race Window

To understand what went wrong, we need to look at how PostgreSQL's Multi-Version Concurrency Control (MVCC) works with transaction snapshots.

### The Problematic Two-Statement Approach

Here's what the "fixed" `poll_for_tasks` function looked like after commit 2f13e8b90:

```sql title="Problematic version (PL/pgSQL with race condition)"
create or replace function pgflow.poll_for_tasks(...)
returns setof pgflow.step_task_record
language plpgsql volatile
as $$
declare
  msg_ids bigint[];
begin
  -- Statement 1: Get message IDs
  select array_agg(msg_id) into msg_ids
  from pgflow.read_with_poll(...);

  -- Statement 2: Process step_tasks (RACE WINDOW!)
  return query with tasks as (
    select * from pgflow.step_tasks
    where message_id = any(msg_ids) and status = 'queued'
  )
  ...
end;
$$;
```

### How the Race Condition Occurred

The critical issue was the **gap between Statement 1 and Statement 2**:

1. **Multiple workers execute Statement 1 simultaneously**
   - Worker A: `msg_ids = [42, 43, 44]`
   - Worker B: `msg_ids = [42, 43, 44]` (identical due to MVCC timing)

2. **Both workers start Statement 2 with fresh MVCC snapshots**
   - Worker A takes snapshot at time T1
   - Worker B takes snapshot at time T2 (microseconds later)
   - Both snapshots see `step_tasks(message_id=42, status='queued')`

3. **Both workers process the same tasks**
   - No row locking prevents this
   - Both call `complete_task` on the same message
   - Second call fails with constraint violation

### Why Production vs Local Development Mattered

| Environment | Hardware | Timing | Race Probability |
|-------------|----------|--------|------------------|
| **Production** | 0.5 vCPU VPS | Workers start within 4-20ms | HIGH |
| **Local** | Fast multi-core | Worker A completes before B starts | LOW |

On slower production hardware, multiple workers were much more likely to start `poll_for_tasks` within the same millisecond window, creating the perfect storm for race conditions.

## The Solution: Two-Phase Polling

The fix required completely rethinking the polling mechanism. Instead of trying to patch the race condition, we moved to a **two-phase approach** that provides atomic task claiming.

### Phase 1: Read Messages

Workers first call `read_with_poll` to claim messages from the queue:

```sql title="Phase 1: Message claiming (atomic)"
select * from pgflow.read_with_poll(
  queue_name, vt, qty, max_poll_seconds, poll_interval_ms
);
```

This function uses `FOR UPDATE SKIP LOCKED` internally, ensuring only one worker can claim each message.

### Phase 2: Start Tasks

Workers then call the new `start_tasks` function with the claimed message IDs:

```sql title="Phase 2: Task processing (race-free)"
create or replace function pgflow.start_tasks(
  flow_slug text,
  msg_ids bigint[],
  worker_id uuid
)
returns setof pgflow.step_task_record
```

This function:
- Finds `step_tasks` matching the message IDs
- Atomically updates them to `status = 'started'`
- Sets `started_at = now()` and `last_worker_id = worker_id`
- Returns task records for execution

### Why Two-Phase Polling Eliminates Race Conditions

1. **Atomic Message Claiming**: `read_with_poll` uses PostgreSQL row locking
2. **Explicit Task Status**: New "started" status makes task ownership visible
3. **Worker Tracking**: `last_worker_id` enables debugging and monitoring
4. **Separate Concerns**: Message polling and task processing are decoupled

## What This Means for You

### Immediate Benefits

- **üîí No more race conditions**: Tasks can't be processed by multiple workers
- **üëÄ Better observability**: See which worker is processing each task
- **üõ°Ô∏è Graceful degradation**: Old workers stop processing (safely) until redeployed
- **üìä Improved monitoring**: Track worker activity and task states

### Breaking Changes

The `poll_for_tasks` function is **deprecated** and now returns an empty set. This ensures old workers won't process tasks incorrectly while providing a clear upgrade path.

<Aside type="caution" title="Worker Behavior During Update">
There will be a small time window where workers won't process tasks while you update. This is intentional and safe‚Äîno tasks will be lost, they'll just wait for updated workers to be deployed.
</Aside>

## How to Update to 0.3.0

Follow these steps to upgrade your pgflow installation:

<Steps>

1. **Update pgflow CLI and apply migrations**
   
   ```bash frame="none"
   npx pgflow@0.3.0 install
   ```
   
   This updates your database schema and adds the new `start_tasks` function.

2. **Update your Edge Worker dependency**
   
   In your Edge Function's `deno.json`:
   
   ```json title="deno.json"
   {
     "imports": {
       "@pgflow/edge-worker": "jsr:@pgflow/edge-worker@0.3.0"
     }
   }
   ```

3. **Update DSL and core packages** (if using them directly)
   
   ```bash frame="none"
   npm install @pgflow/core@0.3.0 @pgflow/dsl@0.3.0
   ```

4. **Apply migrations and deploy Edge Functions**
   
   ```bash frame="none"
   supabase db push
   supabase functions deploy
   ```

</Steps>

### What Happens During the Update

- **Old workers**: Will continue running but won't process new tasks (safe degradation)
- **Database**: New schema supports both old and new polling methods during transition
- **New workers**: Automatically use the improved two-phase polling mechanism

## Technical Details: The New Architecture

For those interested in the implementation details, here's what changed under the hood:

### New Task Status: "started"

The `step_tasks` table now includes:
- `status` can be `'queued'`, `'started'`, `'completed'`, or `'failed'`
- `started_at` timestamp for tracking when task execution began
- `last_worker_id` for identifying which worker is processing the task

### Enhanced Worker Lifecycle

Workers now follow a clearer state progression:

```
1. Poll for messages ‚Üí 2. Start tasks ‚Üí 3. Execute handlers ‚Üí 4. Complete/fail tasks
     (Phase 1)           (Phase 2)         (User code)         (Result handling)
```

This separation makes the system more predictable and easier to debug.

## Looking Forward

This fix demonstrates pgflow's commitment to production-ready reliability. The two-phase polling approach not only eliminates race conditions but also provides better foundation for future features like:

- Enhanced worker monitoring and health checks
- More sophisticated task scheduling strategies  
- Improved error handling and retry mechanisms

---

**Questions or issues with the upgrade?** Join our [Discord community](https://discord.gg/UcKXhfrfan) or [open an issue on GitHub](https://github.com/pgflow-dev/pgflow/issues).