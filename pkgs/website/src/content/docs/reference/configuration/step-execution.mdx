---
title: Step Execution Options
description: Configure retry behavior, timeouts, and error handling for flow steps. Set defaults at flow level, override per step.
sidebar:
  order: 20
---

import { Aside } from '@astrojs/starlight/components';

These settings are defined in your TypeScript flow code and compiled into SQL migrations. They control how individual steps are executed, delayed, and retried. Set defaults at the flow level, override for specific steps. Step-level options are `null` by default, inheriting from flow-level settings.

<Aside type="tip">
  After deployment, you can update these settings without recompiling your flow.
  See [Tune Deployed Flows](/deploy/tune-flow-config/) for details.
</Aside>

## Default Configuration

```typescript
new Flow({
  slug: 'myFlow',
  maxAttempts: 3, // max retry attempts before marking as failed
  baseDelay: 1, // initial retry delay in seconds
  timeout: 60, // visibility timeout in seconds
  // Note: startDelay is step-level only, not available as a default at flow level
});
```

## `maxAttempts`

**Type:** `number`
**Default:** `3`

The maximum number of times a task will be attempted before being marked as permanently failed.

```ts
// Flow level
new Flow({ slug: 'myFlow', maxAttempts: 5 })

  // Step level (overrides flow default)
  .step({ slug: 'myStep', maxAttempts: 7 }, handler);
```

## `baseDelay`

**Type:** `number`
**Default:** `1`

The initial delay (in seconds) before the first retry. pgflow uses exponential backoff, so subsequent retries will have increasingly longer delays.

```ts
// Flow level
new Flow({ slug: 'myFlow', baseDelay: 2 })

  // Step level (overrides flow default)
  .step({ slug: 'myStep', baseDelay: 10 }, handler);
```

## `timeout`

**Type:** `number`
**Default:** `60`

The visibility timeout (in seconds) - how long a task remains invisible to other workers while being processed.

<Aside type="caution" title="Timeout and Task Processing">
Set `timeout` higher than your task's maximum processing time.

<details>
  <summary>Here's why:</summary>- When a worker picks up a task, it becomes
  invisible for `timeout` seconds - If processing takes longer than `timeout`,
  the task becomes visible again - Other workers can then pick up and process
  the same task - This leads to duplicate processing - For example: with
  `timeout: 30` and a task that takes 45 seconds, the task could be processed
  twice
</details>

Currently, pgflow uses timeout only for visibility. In the future, the Edge Worker will also use it to terminate tasks that exceed their timeout.

If a worker crashes during processing, pgflow automatically recovers stalled tasks. See [Troubleshooting Stalled Tasks](/deploy/troubleshooting-stalled-tasks/) for details.

</Aside>

```ts
// Flow level
new Flow({ slug: 'myFlow', timeout: 120 })

  // Step level (overrides flow default)
  .step({ slug: 'myStep', timeout: 300 }, handler);
```

## `startDelay`

**Type:** `number`
**Default:** `0`

Initial delay (in seconds) before task execution.

<Aside type="caution" title="Step-level only">
Unlike other options, `startDelay` cannot be set at the flow level.
<details>
<summary>
Why no flow-level default?
</summary>

Flow-level `startDelay` would create confusing cascading delays in DAG execution:

```
With flow-level startDelay: 10s

Time 0:   Flow starts
Time 10:  Step A starts (waits 10s)
Time 15:  Step A completes
Time 25:  Step B starts (waits 10s after A completes)
Time 30:  Step B completes
Time 40:  Step C starts (waits 10s after B completes)
```

This results in 40+ seconds of delays, not the expected 10s.

</details>

**Better alternatives:**

- **Need uniform delays?** Use a constant as shown below
- **Rate limiting?** Use worker's `maxConcurrent` setting
- **Debug delays?** Add only to specific steps you're debugging
- **Compliance delays?** Make them explicit on relevant steps

To apply the same delay to multiple steps, use a constant:

```typescript
const RATE_LIMIT_DELAY = 2;
flow
  .step({ slug: 'apiCall1', startDelay: RATE_LIMIT_DELAY }, handler1)
  .step({ slug: 'apiCall2', startDelay: RATE_LIMIT_DELAY }, handler2);
```

</Aside>

## Conditional Execution Options

These options control which steps execute based on input patterns and how failures are handled. See [Conditional Steps](/build/conditional-steps/) for detailed explanations and examples.

### `if`

**Type:** `ContainmentPattern<Input>`
**Default:** Not applicable (must be explicitly set)

Run the step only if input contains the specified pattern. pgflow uses PostgreSQL's `@>` containment operator for matching.

```typescript
// Root step - checks flow input
.step({
  slug: 'premiumFeature',
  if: { plan: 'premium' },  // Only run for premium users
}, handler)

// Dependent step - checks dependency output
.step({
  slug: 'notify',
  dependsOn: ['analyze'],
  if: { analyze: { needsAlert: true } },  // Check analyze output
}, handler)
```

<Aside type="note">
The pattern type `ContainmentPattern<Input>` matches the input shape:
- Root steps: Pattern is checked against flow input
- Dependent steps: Pattern is checked against object `{ depSlug: depOutput, ... }`
</Aside>

### `ifNot`

**Type:** `ContainmentPattern<Input>`
**Default:** Not applicable (must be explicitly set)

Run the step only if input does NOT contain the specified pattern.

```typescript
.step({
  slug: 'standardUserFlow',
  ifNot: { role: 'admin' },  // Skip admin users
}, handler)
```

You can combine `if` and `ifNot` - both conditions must be satisfied:

```typescript
.step({
  slug: 'targetedNotification',
  if: { status: 'active' },      // Must be active
  ifNot: { role: 'admin' },       // AND must not be admin
}, handler)
```

### `whenUnmet`

**Type:** `'fail' | 'skip' | 'skip-cascade'`
**Default:** `'skip'`

Controls what happens when `if` or `ifNot` condition is not met.

| Mode             | Behavior                                                                        |
| ---------------- | ------------------------------------------------------------------------------- |
| `'fail'`         | Step fails, entire run fails                                                    |
| `'skip'`         | Step marked as skipped, run continues, dependents receive `undefined` (default) |
| `'skip-cascade'` | Step AND all downstream dependents skipped, run continues                       |

```typescript
.step({
  slug: 'enrichData',
  if: { includeEnrichment: true },
  whenUnmet: 'skip',  // Default - could be omitted
}, handler)

.step({
  slug: 'criticalPath',
  if: { plan: 'premium' },
  whenUnmet: 'fail',  // Explicit - fail if not premium
}, handler)
```

<Aside type="tip">
  The default of `'skip'` means steps with conditions automatically continue the
  workflow rather than failing the entire run.
</Aside>

### `whenExhausted`

**Type:** `'fail' | 'skip' | 'skip-cascade'`
**Default:** `'fail'`

Controls what happens when a step fails after exhausting all `maxAttempts` retry attempts.

| Mode             | Behavior                                                              |
| ---------------- | --------------------------------------------------------------------- |
| `'fail'`         | Step fails, entire run fails (default)                                |
| `'skip'`         | Step marked as skipped, run continues, dependents receive `undefined` |
| `'skip-cascade'` | Step AND all downstream dependents skipped, run continues             |

```typescript
.step({
  slug: 'sendEmail',
  maxAttempts: 3,
  whenExhausted: 'skip',  // Don't fail run if email service is down
}, handler)

.step({
  slug: 'criticalOperation',
  maxAttempts: 5,
  whenExhausted: 'fail',  // Default - fail if operation fails
}, handler)
```

<Aside type="tip">
  Use `whenExhausted: 'skip'` for non-critical steps like notifications,
  analytics, or optional enrichment.
</Aside>

<Aside type="caution" title="TYPE_VIOLATION Errors">
  Programming errors like returning wrong type (e.g., string instead of array
  for map step) always fail the run, regardless of `whenExhausted` setting.
  These are bugs in your code, not runtime conditions.
</Aside>

## Configuration Examples

### Flow with Defaults Only

When all steps can use the same configuration:

```typescript
new Flow({
  slug: 'myFlow',
  maxAttempts: 3, // Default for all steps
  baseDelay: 1, // Default for all steps
  timeout: 60, // Default for all steps
})
  .step({ slug: 'step1' }, handler1) // Uses flow defaults
  .step({ slug: 'step2' }, handler2); // Uses flow defaults
```

### Mixed Configuration

Override flow defaults for specific steps that need different behavior:

```typescript
new Flow({
  slug: 'analyzeData',
  maxAttempts: 3, // Flow defaults
  baseDelay: 1,
  timeout: 60,
})
  .step(
    {
      slug: 'fetchData',
      // Uses all flow defaults
    },
    fetchHandler
  )
  .step(
    {
      slug: 'processData',
      maxAttempts: 5, // Override: more retries
      timeout: 300, // Override: needs more time
      // baseDelay uses flow default (1)
    },
    processHandler
  )
  .step(
    {
      slug: 'callApi',
      baseDelay: 10, // Override: longer initial delay
      // maxAttempts and timeout use flow defaults
    },
    apiHandler
  );
```

## Retry Behavior

pgflow uses **exponential backoff** for retries. The delay between attempts is calculated as:

```
delay = baseDelay * 2^attemptCount
```

<Aside type="note">
  Unlike [Background Jobs
  Mode](/get-started/faq/#what-are-the-two-edge-worker-modes) which supports a
  `maxDelay` cap, Flow Mode retry delays are not capped yet. Delays will
  continue to double with each attempt, at most `maxAttempts`-times, after which
  the step and flow are failed permanently
</Aside>

### Retry Delay Examples

Here's how retry delays grow with different base delays:

| Attempt | Delay (baseDelay: 2s) | Delay (baseDelay: 5s) | Delay (baseDelay: 10s) |
| ------- | --------------------- | --------------------- | ---------------------- |
| 1       | 2s                    | 5s                    | 10s                    |
| 2       | 4s                    | 10s                   | 20s                    |
| 3       | 8s                    | 20s                   | 40s                    |
| 4       | 16s                   | 40s                   | 80s                    |
| 5       | 32s                   | 80s                   | 160s                   |
| 6       | 64s                   | 160s                  | 320s                   |
| 7       | 128s                  | 320s                  | 640s                   |

### When Tasks Fail Permanently

A task is marked as permanently failed when:

- It has been attempted `maxAttempts` times
- Each attempt resulted in an error
- The task status changes from `queued` to `failed`
- The error message from the last attempt is stored
